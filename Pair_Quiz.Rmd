---
title: "Pair Quiz"
author: 
- Jessica Dela Cruz
- John Lester Santos
output: html_document
---
### 1. An article in the Journal of Sound and Vibration ["Measurement of Noise-Evoked Blood Pressure by Means of Averaging Method: Relation between Blood Pressure Rise and PSL" (1991, Vol. 151(3), pp. 383-394)] described a study investigating the relationship between noise exposure and hypertension. The following data are representative of those reported in the article.

#### a. Draw a scatter diagram of y (blood pressure rise in millimeters of mercury) versus x (sound pressure level in decibels). Does a simple linear regression model seem reasonable in this situation?

A Simple Linear Regression model is reasonable to use in this situation because the data lies on a straight line.

```{r, echo=FALSE}
BP_data = read.csv("bp2.csv")

# Add regression line
plot(BP_data$ne,BP_data$bpr, main = "Blood Pressure Rise with Varying Noise Exposure",
     xlab = "Noise Exposure (in db)", ylab = "Blood Pressure Rise",
     pch = 19, frame = FALSE)
abline(lm(BP_data$bpr ~ BP_data$ne, data = BP_data), col = "blue")
```

#### b. Fit the simple linear regression model using least squares. Find an estimate of $\sigma^2$.

```{r, echo=FALSE}
linearMod <- lm(BP_data$bpr ~ BP_data$ne, data=BP_data)
summary(linearMod)
```

```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)

library(here)
library(kableExtra)
library(tidyverse)

dt<-here::here("results7.csv") %>%
  readr::read_csv()
```

```{r, echo=FALSE, results="asis"}
dt %>%
  kbl(caption = "Table 1: Simple Linear Regression Analysis") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```


$$\LARGE \hat{\beta}_1 = 0.174$$
$$\LARGE \hat{\beta}_0 = -10.131$$

#### Fitted Simple Linear Regression Model:

$$\LARGE \hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x = -10.131 + 0.174x$$


#### Estimate of $\sigma^2$: **1.318**

<br><br>

#### c. Find the Predicted Mean Rise with 85 decibels.

$$\LARGE \hat{y} = -10.107 + 0.174(85) = 4.683$$

***

### 2. An article in Optical Engineering ["Operating Curve Extraction of a Correlator's Filter" (2004, Vol. 43, pp. 2775-2779)] reported on the use of an optical correlator to perform an experiment by varying brightness and contrast. The resulting modulation is characterized by the useful range of gray levels. The data follow:

#### A. Fit a multiple linear regression model to these data.

```{r, echo=FALSE}
optic_data = read.csv("optic.csv")
model <- lm(range ~ bright + contrast, data = optic_data)
summary(model)

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)

library(here)
library(kableExtra)
library(tidyverse)

dt<-here::here("results2.csv") %>%
  readr::read_csv()
```

```{r, echo=FALSE, results="asis"}
dt %>%
  kbl(caption = "Table 1: Regression Analysis") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```





#### Fitted Multiple Linear Regression Model:

$$\large Y = \beta_0 +\beta_1 x_1+ \beta_2 x_2 + \epsilon $$
 $$\large =238.6+0.3339x_1-2.717x_2$$

<center>where $Y = Useful\:Range, x_1 = Brightness, x_2= Contrast$</center>


<h4> B. Estimate  $\sigma^2$: </h4>

$$\large \hat{\sigma^2}= RSE^2=(36.35)^2=1321$$

#### C. Compute the standard errors of the regression coefficients.

$$SE_{B_0}=45.23$$
$$SE_{B_1}=0.6763$$ 
$$SE_{B_2}=0.6887$$

#### D. Predict the useful range when brightness = 80 and contrast = 75

$$UsefulRange= 238.6 + 0.3339(brightness) - 2.717(contrast)$$ 
$$=238.6+0.3339(80)-2.717(75)$$ 
<center> <div class="ans">$$=59.737\:ng$$  </div> </center>

#### E. Test for significance of regression using α=0.05. What is the P-value for this test?

<center> <div class="ans"> $P-value=0.01459$  </div> </center>

#### F. Construct a t-test on each regression coefficient. What conclusions can you draw about the variables in this model? Use α=0.05.

<p>**Hypotheses:** </p>
$\large H_0:B_0=0,\: H_1:B_0\neq0$<br>
$\large H_0:B_1=0,\: H_1:B_1\neq0$<br>
$\large H_0:B_2=0,\: H_1:B_2\neq0$<br><br>
<p>**Reject** $H_0:B=0$ **if: the P-value is less than 0.05.** </p>
<p>**Test statistic:** </p>
<p>Based from the table above the t-values are</p>
$$\large t_0=5.27$$
$$\large t_1=0.494$$
$$\large t_2=-3.95$$
<p>**Test statistic:** </p>
<p>Conclusion: We can see from the table that the p-values for $B_0,\:B_1,\:B_2$ are $0.00188,\:0.639 and\: 0.00759$ respectively. Therefore, $H_0:B_0=0\:and\: H_0:B_2=0$ are rejected while $H_0:B_1=0$ is not. </p>
<p>*Practical Interpretation:* The intercept and contrast is significant to the linear regression model while the brightness is not. </p> 


```{css, echo = FALSE}
div.ans {
 position: relative;
  left:30px;
  width:300px;
  background-color: yellow;
}
p {
  font-size: 15px;
}
```








